{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objective\n",
    "\n",
    "_todo: introduction to objective_\n",
    "\n",
    "In order to accomplish this objective, it has been used a connection between Python and R. The reason behind this aciton is mainly driven by the need of a code that is easier to understand and implement, that is why Python is the language used for the code development of this paper.\n",
    "\n",
    "On the other hand, the library that returns the results to Python, is the ECoL library, implemented in R. That'is why there exits the necessity to connect both languages. That is done by using some connecting libraries implemented in both Python and R. \n",
    "\n",
    "For this process, it is created a server process in RStudio using `Rserve`. This allows Python to connect as a client using the library `pyRserve`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_connect(self, operation) :\n",
    "    connection = self.__connection\n",
    "\n",
    "    try:\n",
    "        metric = connection.r(operation)\n",
    "    except :\n",
    "        metric = None\n",
    "        print ('Could not retrieve {}!'.format (operation) )\n",
    "    finally :\n",
    "        return metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This connection allows to implement a aforamentioned link, which calculates the metrics of a dataset in R and it exports those metrics back to the Python environment, where their manipulation is smoother and simpler.\n",
    "\n",
    "The obtained metrics are not altered or tampered with in any part of the process, but it is implemented a dictionary to store those values and be able to associate them to their respective metric domain. The structure uses a key-value organization, where the value is not only formed by the metrics, but also by a message associated with the metrics - which allows later representation of those values:\n",
    "\n",
    "```python\n",
    "metrics.update (\n",
    "    {'<metric_name>': [message, metric_value]}\n",
    ")\n",
    "```\n",
    "\n",
    "The code representing this process is:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics (self, X=None, Y=None):\n",
    "    if X is None and Y is None :\n",
    "        if self.__metrics is not None :\n",
    "            return self.__metrics\n",
    "        else :\n",
    "            # No data and no parameters: finish execution\n",
    "            error_message = '''\n",
    "                No metrics so far! Try given the dataset vector and \n",
    "                target vector as parameters.\\n\n",
    "            '''\n",
    "            raise Exception(error_message)\n",
    "            sys.exit (400)\n",
    "    else :\n",
    "        # Stores connection to R's RPC.\n",
    "        connect = self.__connection\n",
    "\n",
    "        # Sends the input matrix and the output vector to R.\n",
    "        connect.r.X = X\n",
    "        connect.r.y = Y\n",
    "        \n",
    "        # Library to use in R.\n",
    "        connect.r('df_X <- as.data.frame(X)')\n",
    "        connect.r('df_y <- as.data.frame(y)')\n",
    "        connect.r('library(\"ECoL\")')\n",
    "        \n",
    "        ## Metrics, uses a dictionary to provide a faster access to its \n",
    "        # contents.\n",
    "        metrics = {}\n",
    "\n",
    "        # Balance\n",
    "        balance = self.safe_connect('balance(df_X, df_y)') \n",
    "        message = '# Balance (C1, C2):\\t'\n",
    "        balance_dic_entry = { 'balance' : [message, balance] }\n",
    "        \n",
    "        metrics.update (balance_dic_entry)\n",
    "\n",
    "        # Correlation\n",
    "        correlation = self.safe_connect('correlation(df_X, df_y)')\n",
    "        message = '# Correlation (C1, C2, C3, C4):\\t'\n",
    "        correlation_dic_entry = { 'correlation' : [message, correlation] } \n",
    "\n",
    "        metrics.update (correlation_dic_entry)\n",
    "\n",
    "        # Dimensionality\n",
    "        dimensionality = self.safe_connect('dimensionality(df_X, df_y)')\n",
    "        message = '# Dimensionality (T2, T3, T4):'\n",
    "        dimensionality_dic_entry = { 'dimensionality' : [message, dimensionality] }\n",
    "\n",
    "        metrics.update (dimensionality_dic_entry)\n",
    "\n",
    "        # Linearity\n",
    "        linearity = self.safe_connect('linearity(df_X, df_y)')\n",
    "        message = '# Linearity (L1, L2, L3):\\t'\n",
    "        linearity_dic_entry = { 'linearity' : [message, linearity] }\n",
    "\n",
    "        metrics.update (linearity_dic_entry)\n",
    "\n",
    "        # Neighborhood\n",
    "        neighborhood = self.safe_connect('neighborhood(df_X, df_y)')\n",
    "        message = '# Neighborhood (N1, N2, N3, N4, T1, LSC):\\t'\n",
    "        neighborhood_dic_entry = { 'neighborhood' : [message, neighborhood] }\n",
    "\n",
    "        metrics.update (neighborhood_dic_entry)\n",
    "\n",
    "        # Network\n",
    "        network = self.safe_connect('network(df_X, df_y)')\n",
    "        message = '# Network (Density, ClsCoef, Hubs):\\t'\n",
    "        network_dic_entry = { 'network' : [message, network] }\n",
    "\n",
    "        metrics.update (network_dic_entry)\n",
    "\n",
    "        # Overlap\n",
    "        overlap = self.safe_connect('overlapping(df_X, df_y)')\n",
    "        message = '# Overlap (F1, F1v, F2, F3, F4):\\t'\n",
    "        overlap_dic_entry = { 'overlap' : [message, overlap] }\n",
    "\n",
    "        metrics.update (overlap_dic_entry)\n",
    "\n",
    "        # Smoothness\n",
    "        smoothness = self.safe_connect('smoothness(df_X, df_y)')\n",
    "        message = '# Smoothness (S1, S2, S3, S4):\\t'\n",
    "        smoothness_dic_entry = { 'smoothness' : [message, smoothness] }\n",
    "\n",
    "        metrics.update (smoothness_dic_entry)\n",
    "        \n",
    "        self.__metrics = metrics\n",
    "\n",
    "        return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to test the code implementation, it has to be used a dataset on which to try the connection. The `iris dataset` has been the one elected to perform the testing on.\n",
    "\n",
    "That information is loaded and formated so that passing it to R does not return any exception."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'csv' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-a0d74208b979>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mnext\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mcsv_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;31m# Interator object to read the CSV\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     csv_reader = csv.reader (\n\u001b[0m\u001b[0;32m     13\u001b[0m         \u001b[0mcsv_file\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mdelimiter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m','\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'csv' is not defined"
     ]
    }
   ],
   "source": [
    "# Global variables\n",
    "DATASET_PATH = '../dataset/iris.csv'\n",
    "DATASET = []\n",
    "\n",
    "'''\n",
    "    Load Dataset data into an array \n",
    "'''\n",
    "with open (DATASET_PATH, 'r') as csv_file:\n",
    "    # Skip header\n",
    "    next (csv_file)\n",
    "    # Interator object to read the CSV\n",
    "    csv_reader = csv.reader (\n",
    "        csv_file, \n",
    "        delimiter=',', \n",
    "        quoting=csv.QUOTE_ALL\n",
    "    )\n",
    "    # Create array from CSV\n",
    "    for row in csv_reader :\n",
    "        DATASET.append (row)\n",
    "\n",
    "def parse_dataset () : \n",
    "    ## Data\n",
    "    # Input \n",
    "    X = numpy.array (DATASET) # Transformed to numpy array to allow more \n",
    "    X = X[:, 0 : -1]          # operations on it.\n",
    "    X = numpy.array ( [ \n",
    "        numpy.array (row).astype (numpy.float) \n",
    "        for row in X \n",
    "    ] )\n",
    "    # Target\n",
    "    Y = numpy.array( [\n",
    "        row[-1] for row in DATASET\n",
    "    ] )\n",
    "\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the dataset can freely be used and passed to R."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    #Data\n",
    "    inputs, target = parse_dataset ()\n",
    "\n",
    "    # R does not take string values. So each class is translated into a \n",
    "    # numerical value.\n",
    "    for row in range (len(target)) :\n",
    "        if target[row] == 'setosa' :\n",
    "            target[row] = 1\n",
    "        elif target[row] == 'versicolor' :\n",
    "            target[row] = 2\n",
    "        elif target[row] == 'virginica' :\n",
    "            target[row] = 3\n",
    "        else :\n",
    "            target[row] = 0\n",
    "    \n",
    "    # Connect to R\n",
    "    connector = r_connect()\n",
    "    # Compute and print metrics for dataset\n",
    "    connector.get_print_metrics(inputs, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results returned should look like:\n",
    "```bash\n",
    "=== Printing metrics ===\n",
    "\n",
    "# Balance (C1, C2):      <TaggedList(C1=0.9999999999999998, C2=0.0)>\n",
    "# Correlation (C1, C2, C3, C4):  None\n",
    "# Dimensionality (T2, T3, T4): [0.02666667 0.01333333 0.5       ]\n",
    "# Linearity (L1, L2, L3):        <TaggedList(L1=TaggedArray([0.00433569, 0.00750964], key=['mean', 'sd']), L2=TaggedArray([0.01333333, 0.02309401], key=['mean', 'sd']), L3=TaggedArray([0., 0.], key=['mean', 'sd']))>\n",
    "# Neighborhood (N1, N2, N3, N4, T1, LSC):        <TaggedList(N1=0.10666666666666667, N2=TaggedArray([0.19739445, 0.14762821], key=['mean', 'sd']), N3=TaggedArray([0.06      , 0.23828244], key=['mean', 'sd']), N4=TaggedArray([0.01333333, 0.11508192], key=['mean', 'sd']), T1=TaggedArray([0.05555556, 0.09094996], key=['mean', 'sd']), LSC=0.8164)>\n",
    "# Network (Density, ClsCoef, Hubs):      <TaggedList(Density=0.8340044742729307, ClsCoef=0.2652736191628974, Hubs=TaggedArray([0.83805083, 0.27533194], key=['mean', 'sd']))>\n",
    "# Overlap (F1, F1v, F2, F3, F4):         <TaggedList(F1=TaggedArray([0.27981465, 0.26490069], key=['mean', 'sd']), F1v=TaggedArray([0.02677319, 0.03379179], key=['mean', 'sd']), F2=TaggedArray([0.00638177, 0.01105354], key=['mean', 'sd']), F3=TaggedArray([0.12333333, 0.2136196 ], key=['mean', 'sd']), F4=TaggedArray([0.04333333, 0.07505553], key=['mean', 'sd']))>\n",
    "# Smoothness (S1, S2, S3, S4):   None\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

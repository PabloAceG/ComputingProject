%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% Generic template for TFC/TFM/TFG/Tesis
%
% $Id: introduccion.tex,v 1.19 2015/02/24 23:21:54 macias Exp $
%
% By:
%  + Javier Macías-Guarasa. 
%    Departamento de Electrónica
%    Universidad de Alcalá
%  + Roberto Barra-Chicote. 
%    Departamento de Ingeniería Electrónica
%    Universidad Politécnica de Madrid   
% 
% Based on original sources by Roberto Barra, Manuel Ocaña, Jesús Nuevo,
% Pedro Revenga, Fernando Herránz and Noelia Hernández. Thanks a lot to
% all of them, and to the many anonymous contributors found (thanks to
% google) that provided help in setting all this up.
%
% See also the additionalContributors.txt file to check the name of
% additional contributors to this work.
%
% If you think you can add pieces of relevant/useful examples,
% improvements, please contact us at (macias@depeca.uah.es)
%
% Copyleft 2013
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Introduction}\label{chp:intro}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction to Machine Learning}

Through time, humans wanted to keep all memories or thoughts precious to them 
for posterity. Thanks to some technological advancements, larges amounts of 
information can be stored for a relatively cheap price - videos, photographs, 
drawings, weather measures, financial information, academic data, etc. It can 
all be digitalized and kept \textit{forever}. These new possibilities also 
brought new challenges. \textit{What to do with all that information?} Data 
scientists try to manage and make some sense out of the overwhelming new 
information that is being continuously created.

The figure of a data scientist is the one who uses scientific methods, 
processes, algorithms and systems to extract knowledge from structured and 
unstructured data. The algorithms used in data science, are sequences of 
statistical processing steps. Then, there is Machine Learning which uses 
computer algorithms that improve through experience - it is also a subset of 
Artificial Intelligence (AI). In this case, the algorithms are \textit{trained}
to filter and discover patterns and features with massive amounts of data. 

The training and learning processes allow us to make predictions and decisions 
for new data, being advantageous for almost any field: commercial purposes, 
fraud detection, fault prediction, health, environment (climate), network 
traffic, and so on.

The number of machine learning tools/techniques applied in this project is 
quite large and those are further explained in the \textit{Background} 
(Section~\ref{chp:background}). As a brief introduction to the techniques 
and material in this paper, it has been used \texttt{ECoL} R package to obtain 
the complexity metrics of several datasets; the Python's \texttt{scikit-learn} 
package for learning algorithms and some performance metrics for the 
classification algorithms (used through the experiments); as well as the 
\texttt{imbalanced-learn} Python package to deal with imbalanced datasets. The 
resulting scripts allow us the visualization between different tables and plots
for comparing results.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Aim and Objectives}\label{sec:aim-obj}

Here we analyse the complexity metrics proposed by Ho and Basu~\cite{HoB2002} 
in a number of software defect datasets, that have been previously implemented 
in \texttt{ECoL} R package.

The aim of this work is to explore complexity metrics on software defect 
datasets. Also, to analyse how classification algorithms are affected by 
techniques that mitigate imbalance and how that affects the complexity metrics 
previously analysed. To do so, we explore several objectives:

\begin{itemize}
    \item RQ1 How complexity metrics are correlated to the outcome of 
	supervised algorithms?\label{q:rq1}
    \item RQ2 How complexity metrics and imbalance are related?\label{q:rq2}
    \item RQ3 Do complexity metrics tell us something about the quality of the 
	datasets?\label{q:rq3}
\end{itemize}

The purpose of this dissertation is to conduct a study of complexity metrics 
and imbalanced datasets. A comparison between the \textit{raw} data and that 
data after performing some changes that should affect the results: $K$-folding 
Cross Validation (CV), imbalanced techniques, etc.

%%% Local Variables:
%%% TeX-master: "../book"
%%% End:
